[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "AgroClimate Community Cookbook",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books."
  },
  {
    "objectID": "01_weather-data.html#intro",
    "href": "01_weather-data.html#intro",
    "title": "1  Weather and Climate Data",
    "section": "1.1 Intro",
    "text": "1.1 Intro\nTo compute metrics you need daily or hourly weather data. Either observed (i.e., from weather stations) or modeled (i.e., from climate models) data will work.\nMost agroclimate metrics require daily data (daily min temp, daily max temp, daily precip)\nSome require hourly data (e.g., chill portions). If needed, hourly data can be interpolated from daily data (see https://inresgb-lehre.iaas.uni-bonn.de/chillR_book/making-hourly-temperatures.html)\nThings to remember:\n\ndate columns should be converted to R Date class\ndate-time columns should be saved as POSIXct objects\nsee also https://ucanr-igis.github.io/agroclimR/slides/agclimr_slides01.html#(12)\nthink about units"
  },
  {
    "objectID": "01_weather-data.html#cimis-api",
    "href": "01_weather-data.html#cimis-api",
    "title": "1  Weather and Climate Data",
    "section": "1.2 CIMIS API",
    "text": "1.2 CIMIS API\nHow to get data from CIMIS"
  },
  {
    "objectID": "01_weather-data.html#synoptic-api",
    "href": "01_weather-data.html#synoptic-api",
    "title": "1  Weather and Climate Data",
    "section": "1.3 Synoptic API",
    "text": "1.3 Synoptic API\nShow how to get weather data from a weather station on Synoptic, including how to create daily summaries from hourly data\nhttps://ucanr-igis.github.io/sketchbook/synoptic-cimis.html"
  },
  {
    "objectID": "01_weather-data.html#gridmet",
    "href": "01_weather-data.html#gridmet",
    "title": "1  Weather and Climate Data",
    "section": "1.4 gridMet",
    "text": "1.4 gridMet"
  },
  {
    "objectID": "02_metrics-methods.html#load-packages",
    "href": "02_metrics-methods.html#load-packages",
    "title": "2  Methods for Computing Metrics",
    "section": "2.1 Load packages",
    "text": "2.1 Load packages\nAs usual, start by loading a bunch of packages into memory and specifying our package preferences for conflicting function names:\n\nlibrary(caladaptr)\nlibrary(units)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(lubridate)\nlibrary(sf)\n\nSet conflicted preferences:\n\nlibrary(conflicted)\nconflict_prefer(\"filter\", \"dplyr\", quiet = TRUE)\nconflict_prefer(\"count\", \"dplyr\", quiet = TRUE)\nconflict_prefer(\"select\", \"dplyr\", quiet = TRUE)"
  },
  {
    "objectID": "02_metrics-methods.html#fetch-some-sample-data",
    "href": "02_metrics-methods.html#fetch-some-sample-data",
    "title": "2  Methods for Computing Metrics",
    "section": "2.2 Fetch Some Sample Data",
    "text": "2.2 Fetch Some Sample Data\nFor the examples in this chapter, we’ll work with late-century daily temperature data for a location near Bakersfield, CA in the southern San Joaquin Valley.\n\nbkrfld_cap &lt;- ca_loc_pt(coords = c(-119.151062, 35.261321)) |&gt;\n  ca_gcm(gcms[1:4]) |&gt;                                 \n  ca_scenario(c(\"rcp45\", \"rcp85\")) |&gt;\n  ca_period(\"day\") |&gt;\n  ca_years(start = 2070, end = 2099) |&gt;\n  ca_cvar(c(\"tasmin\", \"tasmax\"))\n\nbkrfld_cap |&gt; ca_preflight()\n\nGeneral issues\n - none found\nIssues for querying values\n - none found\nIssues for downloading rasters\n - none found\n\nplot(bkrfld_cap)\n\n\n\n\n\n\n\n\nFetch data:\n\nbkrfld_tbl &lt;- bkrfld_cap |&gt; \n  ca_getvals_tbl(quiet = TRUE) |&gt; \n  mutate(dt = as.Date(dt),\n         temp_f = units::set_units(val, degF))\n\nhead(bkrfld_tbl)\n\n# A tibble: 6 × 9\n     id cvar   period gcm        scenario spag  dt          val temp_f\n  &lt;int&gt; &lt;fct&gt;  &lt;fct&gt;  &lt;fct&gt;      &lt;fct&gt;    &lt;fct&gt; &lt;date&gt;      [K] [degF]\n1     1 tasmin day    HadGEM2-ES rcp45    none  2070-01-01 278.   41.1\n2     1 tasmin day    HadGEM2-ES rcp45    none  2070-01-02 278.   40.6\n3     1 tasmin day    HadGEM2-ES rcp45    none  2070-01-03 284.   51.7\n4     1 tasmin day    HadGEM2-ES rcp45    none  2070-01-04 276.   37.6\n5     1 tasmin day    HadGEM2-ES rcp45    none  2070-01-05 280.   45.0\n6     1 tasmin day    HadGEM2-ES rcp45    none  2070-01-06 280.   44.5"
  },
  {
    "objectID": "02_metrics-methods.html#converting-date-and-time-columns",
    "href": "02_metrics-methods.html#converting-date-and-time-columns",
    "title": "2  Methods for Computing Metrics",
    "section": "2.3 Converting Date and Time Columns",
    "text": "2.3 Converting Date and Time Columns\nBefore you start computing metrics,\n\nDate columns should be converted to R Date class\nDate-time columns should be saved as POSIXct objects\n\nShow code here. Concatenate date part fields with lubridate::make_date() and lubridate::make_datetime()\nIf you need to save your weather data to disk, use a format that knows how to save dates and times (e.g., geopackage, native R data). If you need to save it in a text format (e.g., csv) or as spreadsheet (e.g., xlsx, Google Sheet), use lubridate::format_ISO8601() to write, and lubridate::ymd_hms() to bring it back in."
  },
  {
    "objectID": "02_metrics-methods.html#units",
    "href": "02_metrics-methods.html#units",
    "title": "2  Methods for Computing Metrics",
    "section": "2.4 Units",
    "text": "2.4 Units\nShow them the units package"
  },
  {
    "objectID": "02_metrics-methods.html#time-slicing",
    "href": "02_metrics-methods.html#time-slicing",
    "title": "2  Methods for Computing Metrics",
    "section": "2.5 Time Slicing",
    "text": "2.5 Time Slicing\nOften an analysis requires you to slice climate data into specific periods that are meaningful for a specific study. For example, water years start on October 1 and run through the following season. Or you might just be interested in the winter months, when tree crops or bugs are particularly sensitive to temperatures. In this section, we’ll look at different techniques for time-slicing climate data.\nThe general approach is to add a column in the table that identifies the time slice. (If you’re working with rasters, the idea is similar but you add an attribute value to the layer). Once you have the time-slice identifiers in your table, you can easily filter or group on that column to compute summaries for each time-slice.\nlubridate is your ally when it comes to extracting date parts. For example to add columns for date parts like year, month, week, and ordinal date, we can use the standard mutate() with date part functions from lubridate:\n\nbkrfld_dtprts_tbl &lt;- bkrfld_tbl |&gt; \n  mutate(year = lubridate::year(dt),\n         month = lubridate::month(dt),\n         week = lubridate::week(dt),\n         yday = lubridate::yday(dt)) |&gt; \n  select(dt, year, month, week, yday, cvar, gcm, scenario, temp_f)\n\nbkrfld_dtprts_tbl |&gt; slice(1:20)\n\n# A tibble: 20 × 9\n   dt          year month  week  yday cvar   gcm        scenario temp_f\n   &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;  &lt;fct&gt;      &lt;fct&gt;    [degF]\n 1 2070-01-01  2070     1     1     1 tasmin HadGEM2-ES rcp45      41.1\n 2 2070-01-02  2070     1     1     2 tasmin HadGEM2-ES rcp45      40.6\n 3 2070-01-03  2070     1     1     3 tasmin HadGEM2-ES rcp45      51.7\n 4 2070-01-04  2070     1     1     4 tasmin HadGEM2-ES rcp45      37.6\n 5 2070-01-05  2070     1     1     5 tasmin HadGEM2-ES rcp45      45.0\n 6 2070-01-06  2070     1     1     6 tasmin HadGEM2-ES rcp45      44.5\n 7 2070-01-07  2070     1     1     7 tasmin HadGEM2-ES rcp45      40.9\n 8 2070-01-08  2070     1     2     8 tasmin HadGEM2-ES rcp45      47.7\n 9 2070-01-09  2070     1     2     9 tasmin HadGEM2-ES rcp45      50.5\n10 2070-01-10  2070     1     2    10 tasmin HadGEM2-ES rcp45      46.7\n11 2070-01-11  2070     1     2    11 tasmin HadGEM2-ES rcp45      39.8\n12 2070-01-12  2070     1     2    12 tasmin HadGEM2-ES rcp45      42.9\n13 2070-01-13  2070     1     2    13 tasmin HadGEM2-ES rcp45      35.5\n14 2070-01-14  2070     1     2    14 tasmin HadGEM2-ES rcp45      34.1\n15 2070-01-15  2070     1     3    15 tasmin HadGEM2-ES rcp45      39.4\n16 2070-01-16  2070     1     3    16 tasmin HadGEM2-ES rcp45      43.3\n17 2070-01-17  2070     1     3    17 tasmin HadGEM2-ES rcp45      44.3\n18 2070-01-18  2070     1     3    18 tasmin HadGEM2-ES rcp45      45.5\n19 2070-01-19  2070     1     3    19 tasmin HadGEM2-ES rcp45      49.5\n20 2070-01-20  2070     1     3    20 tasmin HadGEM2-ES rcp45      44.8\n\n\n\n\nTo plot the distribution of winter time daily minimum temperatures (i.e., to identify frost days), we could use the month column to get only dates in December, January, and February:\n\nbkrfld_wintrmth_lows_tbl &lt;- bkrfld_dtprts_tbl |&gt; \n  filter(cvar == \"tasmin\", month %in% c(12, 1, 2))\n  \ntable(bkrfld_wintrmth_lows_tbl$month)\n\n\n   1    2   12 \n7440 6776 7440 \n\n\n\n\nPlot histogram:\n\nggplot(bkrfld_wintrmth_lows_tbl, aes(x=temp_f)) + \n  geom_histogram() +\n  facet_grid(scenario ~ .) +\n  labs(title = \"Distribution of Winter Nightime Lows, 2070-2099\",\n       subtitle = \"Bakersfield, CA\",\n       caption = paste0(\"GCMs: \", paste(gcms[1:4], collapse = \", \"), \". Months: Dec, Jan, and Feb.\"),\n       x = \"night time low (F)\", y = \"count\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\nIf we want use the standard definition of the winter season, we could alternately filter winter days by their ordinal date number (aka Julian date). Winter starts on December 21 (day 355 of non-leap years) and ends on March 20 (day 79).\n\nbkrfld_wintrssn_tbl &lt;- bkrfld_dtprts_tbl |&gt; \n  filter(cvar == \"tasmin\", yday &gt;= 355 | yday &lt;= 79)\n\nggplot(bkrfld_wintrssn_tbl, aes(x=temp_f)) + \n  geom_histogram() +\n  facet_grid(scenario ~ .) +\n  labs(title = \"Distribution of Winter Nightime Lows, 2070-2099\",\n       subtitle = \"Bakersfield, CA\",\n       caption = paste0(\"GCMs: \", paste(gcms[1:4], collapse = \", \"), \". December 21 - March 20.\"),\n       x = \"night time low (F)\", y = \"count\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\nTime slices can also be used for grouping. The following expression computes the average nightly low for the summer months for each RCP (all GCMs and years combined):\n\nbkrfld_dtprts_tbl |&gt; \n  filter(month %in% 6:8, cvar == \"tasmin\") |&gt; \n  group_by(month, scenario) |&gt; \n  summarise(avg_temp = mean(temp_f), .groups = \"drop\") |&gt; \n  mutate(month = month.name[month]) |&gt; \n  tidyr::pivot_wider(id_cols = month, names_from = scenario, values_from = avg_temp)\n\n# A tibble: 3 × 3\n  month   rcp45  rcp85\n  &lt;chr&gt;  [degF] [degF]\n1 June     68.1   71.5\n2 July     74.1   78.0\n3 August   73.8   77.8\n\n\n\n\nSometimes the time period of interest spans two calendar years. A water year for example starts on October 1 and goes thru the end of September the following year. Some agricultural periods (such as winter dormancy) may also start in the fall and continue into the new year.\nSlicing your data by a time period that spans calendar years is done in the same manner - you add a column to the table for period identifier. Below we add a column for water year (which conventionally are designated by the calendar year in which it ends):\n\nbkrfld_wtryr_tbl &lt;- bkrfld_tbl |&gt; \n  mutate(water_yr = year(dt) + if_else(month(dt) &gt;= 10, 1, 0)) |&gt; \n  select(dt, water_yr, cvar, gcm, scenario, temp_f)\n\nbkrfld_wtryr_tbl |&gt; sample_n(10)\n\n# A tibble: 10 × 6\n   dt         water_yr cvar   gcm        scenario temp_f\n   &lt;date&gt;        &lt;dbl&gt; &lt;fct&gt;  &lt;fct&gt;      &lt;fct&gt;    [degF]\n 1 2076-05-25     2076 tasmin CNRM-CM5   rcp85      76.3\n 2 2087-02-14     2087 tasmax CanESM2    rcp85      66.1\n 3 2078-07-22     2078 tasmin CNRM-CM5   rcp85      77.5\n 4 2070-10-29     2071 tasmin MIROC5     rcp45      56.4\n 5 2085-06-12     2085 tasmin CNRM-CM5   rcp45      69.9\n 6 2082-05-05     2082 tasmax CanESM2    rcp85      83.9\n 7 2075-06-28     2075 tasmin MIROC5     rcp45      65.5\n 8 2089-10-11     2090 tasmax CanESM2    rcp85      93.7\n 9 2097-04-08     2097 tasmin CNRM-CM5   rcp45      57.1\n10 2085-01-12     2085 tasmin HadGEM2-ES rcp45      44.1"
  },
  {
    "objectID": "02_metrics-methods.html#daily-climate-metrics",
    "href": "02_metrics-methods.html#daily-climate-metrics",
    "title": "2  Methods for Computing Metrics",
    "section": "2.6 Daily Climate Metrics",
    "text": "2.6 Daily Climate Metrics\nMany climate analyses require metrics computed on a daily time scale. For example, to see how frost exposure might change over time, we may have to look at the lowest daily temperature. This presents a small conundrum, because climate models are not weather forecasts, and best practices tell us that we don’t look at less than 30 years. But it would be silly to average the daily low temperatures by month or year and use that as a proxy for frost exposure.\nThe general approach in these cases is compute the daily metrics as if you were dealing with observed data, but then to aggregate the metrics over bigger periods of time and space. For example, you could classify each individual day in frost / non-frost, and then count the number of predicted frost days over a 30-year interval."
  },
  {
    "objectID": "02_metrics-methods.html#diurnal-temperature-range",
    "href": "02_metrics-methods.html#diurnal-temperature-range",
    "title": "2  Methods for Computing Metrics",
    "section": "2.7 Diurnal Temperature Range",
    "text": "2.7 Diurnal Temperature Range\nDiurnal Temperature Range (DTR) is the difference between daily min and max temperature (Parker et al. 2022). The magnitude of DTR can impact wine grape development and taste. In the example below, we calculate DTR from November thru February.\nThe first step is to separate the minimum and maximum daily temperatures into separate columns:\n\nbkrfld_wide_tbl &lt;- bkrfld_tbl |&gt; \n  filter(month(dt) %in% c(11,12,1,2)) |&gt; \n  tidyr::pivot_wider(id_cols = c(dt, gcm, scenario), names_from = cvar, values_from = temp_f)\n\nhead(bkrfld_wide_tbl)\n\n# A tibble: 6 × 5\n  dt         gcm        scenario tasmin tasmax\n  &lt;date&gt;     &lt;fct&gt;      &lt;fct&gt;    [degF] [degF]\n1 2070-01-01 HadGEM2-ES rcp45      41.1   67.2\n2 2070-01-02 HadGEM2-ES rcp45      40.6   63.2\n3 2070-01-03 HadGEM2-ES rcp45      51.7   67.0\n4 2070-01-04 HadGEM2-ES rcp45      37.6   53.9\n5 2070-01-05 HadGEM2-ES rcp45      45.0   54.8\n6 2070-01-06 HadGEM2-ES rcp45      44.5   57.9\n\n\nNow we can compute DTR:\n\nbkrfld_dtr_tbl &lt;- bkrfld_wide_tbl |&gt; \n  mutate(dtr = tasmax - tasmin)\n\nbkrfld_dtr_tbl |&gt; head()\n\n# A tibble: 6 × 6\n  dt         gcm        scenario tasmin tasmax    dtr\n  &lt;date&gt;     &lt;fct&gt;      &lt;fct&gt;    [degF] [degF] [degF]\n1 2070-01-01 HadGEM2-ES rcp45      41.1   67.2  26.1 \n2 2070-01-02 HadGEM2-ES rcp45      40.6   63.2  22.7 \n3 2070-01-03 HadGEM2-ES rcp45      51.7   67.0  15.3 \n4 2070-01-04 HadGEM2-ES rcp45      37.6   53.9  16.3 \n5 2070-01-05 HadGEM2-ES rcp45      45.0   54.8   9.85\n6 2070-01-06 HadGEM2-ES rcp45      44.5   57.9  13.4 \n\n\n\n\nWe can show the results with a box plot:\n\nggplot(bkrfld_dtr_tbl, aes(x=scenario, y = dtr)) + \n  geom_boxplot() + \n  labs(title = \"Diurnal Temperature Range, 2070-2099\",\n       subtitle = \"Bakersfield, CA\", \n       caption = paste0(\"GCMs: \", paste(gcms[1:4], collapse = \", \"), \". Temporal period: Nov-Feb.\"),\n       x = \"Emission scenarios\", y = \"diurnal temperature range\")"
  },
  {
    "objectID": "02_metrics-methods.html#daily-threshhold-events",
    "href": "02_metrics-methods.html#daily-threshhold-events",
    "title": "2  Methods for Computing Metrics",
    "section": "2.8 Daily Threshhold Events",
    "text": "2.8 Daily Threshhold Events\nMany climate analyses involve a threshold event, such as temperature above or below a certain value. These tend to be easy to compute using an expression that returns TRUE or FALSE. Subsequently, you can count the number of threshold events using sum() (when you sum logical values TRUEs become 1 and FALSE becomes 0).\nBelow we compute the number of ‘Hot Days’ per year, where a Hot Day is defined as the maximum temperature over 38 °C (100.4 °F) (Parker et al. 2022). We need to keep gcm and scenario as we’ll be grouping on those columns next.\n\nbkrfld_hotday_tbl &lt;- bkrfld_tbl |&gt; \n  filter(cvar == \"tasmax\") |&gt; \n  mutate(hotday_yn = temp_f &gt;= units::set_units(38, degC),\n         year = year(dt)) |&gt; \n  select(dt, year, cvar, scenario, gcm, temp_f, hotday_yn)\n\nbkrfld_hotday_tbl |&gt; head()\n\n# A tibble: 6 × 7\n  dt          year cvar   scenario gcm        temp_f hotday_yn\n  &lt;date&gt;     &lt;dbl&gt; &lt;fct&gt;  &lt;fct&gt;    &lt;fct&gt;      [degF] &lt;lgl&gt;    \n1 2070-01-01  2070 tasmax rcp45    HadGEM2-ES   67.2 FALSE    \n2 2070-01-02  2070 tasmax rcp45    HadGEM2-ES   63.2 FALSE    \n3 2070-01-03  2070 tasmax rcp45    HadGEM2-ES   67.0 FALSE    \n4 2070-01-04  2070 tasmax rcp45    HadGEM2-ES   53.9 FALSE    \n5 2070-01-05  2070 tasmax rcp45    HadGEM2-ES   54.8 FALSE    \n6 2070-01-06  2070 tasmax rcp45    HadGEM2-ES   57.9 FALSE    \n\n\n\n\nNow we can group by year and scenario to compare how the average number of hot days per year looks for each RCP.\n\nbkrfld_numhd_tbl &lt;- bkrfld_hotday_tbl |&gt; \n  group_by(year, scenario, gcm) |&gt; \n  summarise(num_hotday = sum(hotday_yn))\n\n`summarise()` has grouped output by 'year', 'scenario'. You can override using\nthe `.groups` argument.\n\nbkrfld_numhd_tbl |&gt; head()\n\n# A tibble: 6 × 4\n# Groups:   year, scenario [2]\n   year scenario gcm        num_hotday\n  &lt;dbl&gt; &lt;fct&gt;    &lt;fct&gt;           &lt;int&gt;\n1  2070 rcp45    CanESM2            75\n2  2070 rcp45    CNRM-CM5           58\n3  2070 rcp45    HadGEM2-ES         91\n4  2070 rcp45    MIROC5             70\n5  2070 rcp85    CanESM2            88\n6  2070 rcp85    CNRM-CM5           68\n\nbkrfld_numhd_tbl |&gt; \n  group_by(year, scenario) |&gt; \n  summarize(avg_hd = mean(num_hotday), .groups = \"drop\") |&gt; \n  tidyr::pivot_wider(id_cols = year, names_from = scenario, values_from = avg_hd)\n\n# A tibble: 30 × 3\n    year rcp45 rcp85\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  2070  73.5  87.5\n 2  2071  73.2  83  \n 3  2072  75    83.5\n 4  2073  77.5  94.2\n 5  2074  83.5  88.5\n 6  2075  77.5  79  \n 7  2076  71    87  \n 8  2077  65.2  98.2\n 9  2078  70.2  94.8\n10  2079  82   102  \n# ℹ 20 more rows\n\n\nSometimes you want to know the number of threshold events during a particular time of the year. For example tree crops are particularly susceptible to frost damage right after they’ve bloomed.\nLet’s compute the number of hot days in June, July and August, which can be particularly bad for nut development. Because we have daily data from 4 GCMs, we have to count the number of hot days for each GCM, and then average those together for each emissions scenario.\n\nbkrfld_sumrhd_tbl &lt;- bkrfld_tbl |&gt; \n  filter(cvar == \"tasmax\", month(dt) %in% c(6,7,8)) |&gt; \n  mutate(hd = temp_f &gt;= units::set_units(38, degC),\n         year = year(dt)) |&gt; \n  select(dt, year, cvar, scenario, gcm, temp_f, hd)\n\nbkrfld_sumrhd_tbl |&gt; head()\n\n# A tibble: 6 × 7\n  dt          year cvar   scenario gcm        temp_f hd   \n  &lt;date&gt;     &lt;dbl&gt; &lt;fct&gt;  &lt;fct&gt;    &lt;fct&gt;      [degF] &lt;lgl&gt;\n1 2070-06-01  2070 tasmax rcp45    HadGEM2-ES   79.8 FALSE\n2 2070-06-02  2070 tasmax rcp45    HadGEM2-ES   77.7 FALSE\n3 2070-06-03  2070 tasmax rcp45    HadGEM2-ES   74.7 FALSE\n4 2070-06-04  2070 tasmax rcp45    HadGEM2-ES   80.6 FALSE\n5 2070-06-05  2070 tasmax rcp45    HadGEM2-ES   86.3 FALSE\n6 2070-06-06  2070 tasmax rcp45    HadGEM2-ES   92.9 FALSE\n\n\n\n\n\nbkrfld_numsumrhd_tbl &lt;- bkrfld_sumrhd_tbl |&gt; \n  group_by(year, scenario, gcm) |&gt; \n  summarise(num_sumrhd = sum(hd), .groups = \"drop\") \n\nbkrfld_numsumrhd_tbl |&gt; head()\n\n# A tibble: 6 × 4\n   year scenario gcm        num_sumrhd\n  &lt;dbl&gt; &lt;fct&gt;    &lt;fct&gt;           &lt;int&gt;\n1  2070 rcp45    CanESM2            64\n2  2070 rcp45    CNRM-CM5           43\n3  2070 rcp45    HadGEM2-ES         71\n4  2070 rcp45    MIROC5             55\n5  2070 rcp85    CanESM2            69\n6  2070 rcp85    CNRM-CM5           55\n\n\n\n\n\nbkrfld_avgnumsumrhd_tbl &lt;- bkrfld_numsumrhd_tbl |&gt; \n  group_by(year, scenario) |&gt; \n  summarise(avg_num_sumrhd = mean(num_sumrhd), .groups = \"drop\")\n\nbkrfld_avgnumsumrhd_tbl |&gt; head()\n\n# A tibble: 6 × 3\n   year scenario avg_num_sumrhd\n  &lt;dbl&gt; &lt;fct&gt;             &lt;dbl&gt;\n1  2070 rcp45              58.2\n2  2070 rcp85              66.5\n3  2071 rcp45              56.8\n4  2071 rcp85              59  \n5  2072 rcp45              60.5\n6  2072 rcp85              62.2\n\n\n\n\n\nbkrfld_avgnumsumrhd_tbl |&gt; \n  tidyr::pivot_wider(id_cols = year, names_from = scenario, values_from = avg_num_sumrhd)\n\n# A tibble: 30 × 3\n    year rcp45 rcp85\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  2070  58.2  66.5\n 2  2071  56.8  59  \n 3  2072  60.5  62.2\n 4  2073  65    72  \n 5  2074  63.5  69.2\n 6  2075  59.8  55.2\n 7  2076  56.5  70  \n 8  2077  54    70  \n 9  2078  59    72.5\n10  2079  59.8  74.2\n# ℹ 20 more rows"
  },
  {
    "objectID": "02_metrics-methods.html#counting-consecutive-events",
    "href": "02_metrics-methods.html#counting-consecutive-events",
    "title": "2  Methods for Computing Metrics",
    "section": "2.9 Counting Consecutive Events",
    "text": "2.9 Counting Consecutive Events\n“Heat spells”, “cold spells”, and “extreme precipitation” events are all defined as consecutive days of a threshold event. The number of consecutive days may vary, but the general technique for identifying ‘spells’ is\n\nRun an expression that tests whether the threshhold was passed for each day, returning a series TRUE or FALSE values.\nPass the TRUE / FALSE values into the rle(), which identifies ‘runs’ of TRUE and FALSE values\nCount the number of runs that meet the minimum duration\n\nTo illustrate this, take the following series of 30 temperature values. We’ll compute the number of heat spells where the temperature was 100 or more for three or more days in a row:\n\nx_temp &lt;- c(96,97,101,98,100,102,101,99,94,89,97,102,104,101,103,99,92,94,88,90,98,101,99,103,104,102,98,97,98,99)\n\nStep 1 is to check to see if each value exceeds the threshold):\n\nx_hot &lt;- x_temp &gt;= 100\nx_hot\n\n [1] FALSE FALSE  TRUE FALSE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE  TRUE\n[13]  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE  TRUE\n[25]  TRUE  TRUE FALSE FALSE FALSE FALSE\n\n\nNext, feed the 30 TRUE/FALSE values into rle() (run-length encoding):\n\nrle_lst &lt;- rle(x_hot)\nrle_lst\n\nRun Length Encoding\n  lengths: int [1:11] 2 1 1 3 4 4 6 1 1 3 ...\n  values : logi [1:11] FALSE TRUE FALSE TRUE FALSE TRUE ...\n\n\nrle() returns a list with two elements. Both elements are vectors of the same length. The lengths element contains the number of contiguous identical elements found in a ‘run’ in the original data. The values element contains the corresponding value of the run (in this case TRUE/FALSE values. Using this info, we can see our original data started with two FALSE values, followed by one TRUE value, followed by one FALSE value, followed by three TRUE values, and so on.\nTo count the number of ‘TRUE’ runs (aka spells) equal to or longer than n days, we can apply a simple expression:\n\nsum(rle_lst$values & rle_lst$lengths &gt;= 3)\n\n[1] 3\n\n\n\n\nUsing these techniques, below we compute the number of heat spells where the temperature was 100 °F or more for three or more days in a row:\n\nbkrfld_sumrhd_tbl &lt;- bkrfld_tbl |&gt; \n  filter(cvar == \"tasmax\", month(dt) %in% c(6,7,8)) |&gt; \n  mutate(hd = temp_f &gt;= units::set_units(38, degC),\n         year = year(dt)) |&gt; \n  select(dt, year, cvar, scenario, gcm, temp_f, hd)\n\nbkrfld_sumrhd_tbl |&gt; head()\n\n# A tibble: 6 × 7\n  dt          year cvar   scenario gcm        temp_f hd   \n  &lt;date&gt;     &lt;dbl&gt; &lt;fct&gt;  &lt;fct&gt;    &lt;fct&gt;      [degF] &lt;lgl&gt;\n1 2070-06-01  2070 tasmax rcp45    HadGEM2-ES   79.8 FALSE\n2 2070-06-02  2070 tasmax rcp45    HadGEM2-ES   77.7 FALSE\n3 2070-06-03  2070 tasmax rcp45    HadGEM2-ES   74.7 FALSE\n4 2070-06-04  2070 tasmax rcp45    HadGEM2-ES   80.6 FALSE\n5 2070-06-05  2070 tasmax rcp45    HadGEM2-ES   86.3 FALSE\n6 2070-06-06  2070 tasmax rcp45    HadGEM2-ES   92.9 FALSE\n\n\nWe have to be a little creative to apply rle() in a data frame that has many time series in it (e.g., multiple years, GCMs, and emission scenarios). Each of the series needs to be fed into rle() individually, and the list returned by rle() will have different lengths. But what we can do is set up a list structure to store the results of rle().\nFirst, we create a grouped tibble. A group tibble is still a tibble, but also has groups of rows invisibly defined. As we shall see shortly, other functions know what to do with those groups.\n\nbkrfld_grps_tbl &lt;- bkrfld_sumrhd_tbl |&gt; \n  group_by(year, scenario, gcm) |&gt; \n  arrange(dt)\n\nglimpse(bkrfld_grps_tbl)\n\nRows: 22,080\nColumns: 7\nGroups: year, scenario, gcm [240]\n$ dt       &lt;date&gt; 2070-06-01, 2070-06-01, 2070-06-01, 2070-06-01, 2070-06-01, …\n$ year     &lt;dbl&gt; 2070, 2070, 2070, 2070, 2070, 2070, 2070, 2070, 2070, 2070, 2…\n$ cvar     &lt;fct&gt; tasmax, tasmax, tasmax, tasmax, tasmax, tasmax, tasmax, tasma…\n$ scenario &lt;fct&gt; rcp45, rcp45, rcp45, rcp45, rcp85, rcp85, rcp85, rcp85, rcp45…\n$ gcm      &lt;fct&gt; HadGEM2-ES, CNRM-CM5, CanESM2, MIROC5, HadGEM2-ES, CNRM-CM5, …\n$ temp_f   [degF] 79.84528 [degF], 106.15573 [degF], 90.13398 [degF], 95.24855…\n$ hd       &lt;lgl&gt; FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, …\n\n\n\n\nNext, we have to write a function that we can feed into group_modify(). If you read the documentation for group_modify(), it says the first two arguments of the function should accept i) a group of rows (as a tibble), ii) the properties of the group (e.g., which year, scenario, and gcm) as a 1-row tibble. our function should also return a tibble, that will be stacked for all the groups. In addition, group_modify() will also automatically include columns for the grouping variables.\nIn our case, all we need is the number of heatspells so the function only has to return a 1x1 tibble.\n\nnum_heatspells &lt;- function(data_tbl, key_tbl, num_days = 3) {\n  ## Feed the hd column into rle()\n  rle_lst &lt;- rle(data_tbl$hd)\n  \n  ## Return a tibble with one row\n  tibble(num_spells = sum(rle_lst$values & rle_lst$lengths &gt;= num_days))\n}\n\n\n\nNow we can apply this function to every group:\n\nbkrfld_numspells_tbl &lt;- bkrfld_grps_tbl |&gt; \n  group_modify(.f = num_heatspells, num_days = 3)\n\nbkrfld_numspells_tbl |&gt; head()\n\n# A tibble: 6 × 4\n# Groups:   year, scenario, gcm [6]\n   year scenario gcm        num_spells\n  &lt;dbl&gt; &lt;fct&gt;    &lt;fct&gt;           &lt;int&gt;\n1  2070 rcp45    CanESM2             7\n2  2070 rcp45    CNRM-CM5            6\n3  2070 rcp45    HadGEM2-ES          5\n4  2070 rcp45    MIROC5              5\n5  2070 rcp85    CanESM2             3\n6  2070 rcp85    CNRM-CM5            6\n\n\nLastly, we can compute the average number of heatspells per emissions scenario:\n\nbkrfld_numspells_tbl |&gt; \n  group_by(scenario) |&gt; \n  summarise(avg_spells = mean(num_spells)) \n\n# A tibble: 2 × 2\n  scenario avg_spells\n  &lt;fct&gt;         &lt;dbl&gt;\n1 rcp45          4.79\n2 rcp85          3.98\n\n\n\n\n\n\nParker, Lauren E., Ning Zhang, John T. Abatzoglou, Steven M. Ostoja, and Tapan B. Pathak. 2022. “Observed Changes in Agroclimate Metrics Relevant for Specialty Crop Production in California.” Agronomy 12 (1): 205. https://doi.org/10.3390/agronomy12010205."
  },
  {
    "objectID": "03_agroclimate-metrics.html#load-packages",
    "href": "03_agroclimate-metrics.html#load-packages",
    "title": "3  AgroClimate Metrics",
    "section": "3.1 Load Packages",
    "text": "3.1 Load Packages\nAs usual, we start by loading a bunch of packages into memory and specifying our preferences for conflicting function names:\n\nlibrary(caladaptr)\nlibrary(units)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(lubridate)\nlibrary(sf)\n\nSet conflicted preferences:\n\nlibrary(conflicted)\nconflict_prefer(\"filter\", \"dplyr\", quiet = TRUE)\nconflict_prefer(\"count\", \"dplyr\", quiet = TRUE)\nconflict_prefer(\"select\", \"dplyr\", quiet = TRUE)"
  },
  {
    "objectID": "03_agroclimate-metrics.html#fetch-some-data",
    "href": "03_agroclimate-metrics.html#fetch-some-data",
    "title": "3  AgroClimate Metrics",
    "section": "3.2 Fetch Some Data",
    "text": "3.2 Fetch Some Data\nTo compute agroclimate metrics, we’ll first get 20 years of observed data from the gridMet dataset for a location in Colusa County in the Sacramento Valley.\n\ncolusa_cap &lt;- ca_loc_pt(coords = c(-122.159304, 39.289291)) %&gt;%\n  ca_slug(c(\"tmmn_day_gridmet\", \"tmmx_day_gridmet\")) %&gt;%\n  ca_years(start = 2000, end = 2020) \n\ncolusa_cap\n\nCal-Adapt API Request\nLocation(s): \n  x: -122.159\n  y: 39.289\nSlug(s): tmmn_day_gridmet, tmmx_day_gridmet\nDates: 2000-01-01 to 2020-12-31\n \n\ncolusa_cap %&gt;% ca_preflight()\n\nGeneral issues\n - none found\nIssues for querying values\n - none found\nIssues for downloading rasters\n - none found\n\nplot(colusa_cap)\n\n\n\n\n\n\n\n\nNext we fetch the data. While we’re at it, we’ll add columns for the climate variable (based on the slug), year, and temperature in Fahrenheit:\n\ncolusa_tbl &lt;- colusa_cap %&gt;% \n  ca_getvals_tbl() %&gt;% \n  mutate(dt = as.Date(dt),\n         year = year(as.Date(dt)),\n         cvar = substr(slug, 1, 4),\n         temp_f = units::set_units(val, degF)) %&gt;% \n  select(year, dt, cvar, temp_f)\n\nglimpse(colusa_tbl)\n\nRows: 15,342\nColumns: 4\n$ year   &lt;dbl&gt; 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 200…\n$ dt     &lt;date&gt; 2000-01-01, 2000-01-02, 2000-01-03, 2000-01-04, 2000-01-05, 20…\n$ cvar   &lt;chr&gt; \"tmmn\", \"tmmn\", \"tmmn\", \"tmmn\", \"tmmn\", \"tmmn\", \"tmmn\", \"tmmn\",…\n$ temp_f [degF] 32.45 [degF], 30.11 [degF], 32.09 [degF], 39.11 [degF], 32.27 …"
  },
  {
    "objectID": "03_agroclimate-metrics.html#growing-degree-days",
    "href": "03_agroclimate-metrics.html#growing-degree-days",
    "title": "3  AgroClimate Metrics",
    "section": "3.3 Growing Degree Days",
    "text": "3.3 Growing Degree Days\nGrowing Degree Days (GDD) are a measure of accumulated heat starting from a specific date / event. You may wonder - what’s the point of tracking accumulated heat, given that it cools down every night? The answer is because many plants seem to keep track of accumulated heat units. Research has shown that many phenological events, like the emergence of fruit, are strongly correlated with accumulated heat, also known as thermal time. Insect phenology is likewise strongly correlated with heat units.\nThere are a few ways of computing GDD. Parker et al. (2022) recommend the simple average method with a base temperature of 10 °C:\n\n\\(GDD = (temp_{max} - temp_{min}) / 2 - temp_{base}\\)\n\nNegative GDD values are not biologically meaningful (i.e., plant development generally doesn’t go backwards), so negative GDD values are generally converted to 0 (i.e., Method 1 described by McMaster and Wilhelm (1997)).\nComputing daily GDD is fairly straight-forward. We just have to remember to zero-out negative GDD values:\n\n(tbase_c &lt;- set_units(10, degC))                           ## base temp\n\n10 [°C]\n\ncolusa_gdd_tbl &lt;- colusa_tbl %&gt;% \n  mutate(temp_c = set_units(temp_f, degC)) %&gt;%             ## create a degC column\n  pivot_wider(id_cols = c(year, dt),                       ## make min and max temps separate colums\n              names_from = cvar, \n              values_from = temp_c) %&gt;% \n  mutate(gdd = as.numeric(((tmmx+tmmn)/2) - tbase_c)) %&gt;%  ## compute gdd as a numeric value\n  mutate(gdd = if_else(gdd &lt; 0, 0, gdd))                   ## zero-out negative values\n\ncolusa_gdd_tbl %&gt;% head()\n\n# A tibble: 6 × 5\n   year dt            tmmn  tmmx   gdd\n  &lt;dbl&gt; &lt;date&gt;        [°C]  [°C] &lt;dbl&gt;\n1  2000 2000-01-01  0.250  12.7      0\n2  2000 2000-01-02 -1.05   12.2      0\n3  2000 2000-01-03  0.0500 14.2      0\n4  2000 2000-01-04  3.95    9.65     0\n5  2000 2000-01-05  0.150  14.2      0\n6  2000 2000-01-06 -1.35   12.6      0\n\n\n\n\nApplying GDD to predict crop development requires 1) a start date (also known as a biofix date), and 2) a crop phenology table. These are not shown here, but are not hard to apply (for an example see the Pistachio Nut Development Decision Support tool)."
  },
  {
    "objectID": "03_agroclimate-metrics.html#chill-accumulation",
    "href": "03_agroclimate-metrics.html#chill-accumulation",
    "title": "3  AgroClimate Metrics",
    "section": "3.4 Chill Accumulation",
    "text": "3.4 Chill Accumulation\nChill accumulation is similar to growing degree days, but for cold. In other words, there are a few phenological events that appear to be strongly correlated with the accumulated amount of chill. An example of this is flowering for many tree crops. Apparently, the trees keep an internal ledger of how cold its been during the winter, and for how long. They use this internal record use to decide when it’s time to come out of their winter dormancy and start flowering. This mechanism probably evolved to help them avoid frost damage.\nResearchers have looked at a number of ways to measure accumulated chill, and the one that does the best job at predicting phenology events is called Chill Portions (CP) (Luedeling and Brown 2011). The calculations are a bit complicated, but fortunately there’s a R-package that will compute chill portions. For more info, see here."
  },
  {
    "objectID": "03_agroclimate-metrics.html#frost-days",
    "href": "03_agroclimate-metrics.html#frost-days",
    "title": "3  AgroClimate Metrics",
    "section": "3.5 Frost Days",
    "text": "3.5 Frost Days\nFrost Days (FD) are the number of days per year with minimum temperatures (Tn) ≤ 0 °C (Parker et al. 2022). They can be computed with:\n\ncolusa_fd_tbl &lt;- colusa_tbl %&gt;% \n  filter(cvar == \"tmmn\", temp_f &lt;= set_units(0, degC)) %&gt;% \n  group_by(year) %&gt;% \n  summarise(fd = n())\n\ncolusa_fd_tbl\n\n# A tibble: 21 × 2\n    year    fd\n   &lt;dbl&gt; &lt;int&gt;\n 1  2000     9\n 2  2001    14\n 3  2002    16\n 4  2003    10\n 5  2004     9\n 6  2005     5\n 7  2006    11\n 8  2007    23\n 9  2008     8\n10  2009    24\n# ℹ 11 more rows"
  },
  {
    "objectID": "03_agroclimate-metrics.html#last-spring-and-first-fall-freeze",
    "href": "03_agroclimate-metrics.html#last-spring-and-first-fall-freeze",
    "title": "3  AgroClimate Metrics",
    "section": "3.6 Last Spring and First Fall Freeze",
    "text": "3.6 Last Spring and First Fall Freeze\nThe Last Spring Freeze (LSF) is defined as the last day of the calendar year prior to 30 June with a Tn ≤ 0 °C. Conversely the First Fall Freeze (FFF) is defined as the first day of the calendar year commencing 1 July with Tn ≤ 0 °C (Parker et al. 2022).\nWe can find the last freeze date by chaining together dplyr expressions that i) keep only ‘freeze days’ from January through June, ii) group the freeze days by year, and iii) taking the max date for each group:\n\ncolusa_lf_tbl &lt;- colusa_tbl %&gt;% \n  filter(cvar == \"tmmn\", month(dt) &lt;= 6, temp_f &lt;= set_units(32, degF)) %&gt;% \n  group_by(year) %&gt;% \n  summarise(lf = max(dt))\n\ncolusa_lf_tbl\n\n# A tibble: 20 × 2\n    year lf        \n   &lt;dbl&gt; &lt;date&gt;    \n 1  2000 2000-01-28\n 2  2001 2001-04-10\n 3  2002 2002-03-18\n 4  2003 2003-02-08\n 5  2004 2004-01-05\n 6  2005 2005-01-30\n 7  2006 2006-02-20\n 8  2007 2007-03-01\n 9  2008 2008-04-20\n10  2009 2009-03-23\n11  2011 2011-02-28\n12  2012 2012-03-23\n13  2013 2013-02-26\n14  2014 2014-02-04\n15  2015 2015-01-03\n16  2016 2016-01-01\n17  2017 2017-02-28\n18  2018 2018-03-05\n19  2019 2019-01-04\n20  2020 2020-01-04\n\n\n\n\nSimilarly, we can find the first fall freeze by keeping only dates from July - December where the temperature dipped below freezing, then taking the minimum date for each year:\n\ncolusa_fff_tbl &lt;- colusa_tbl %&gt;% \n  filter(cvar == \"tmmn\", month(dt) &gt;= 7, temp_f &lt;= set_units(32, degF)) %&gt;%\n  group_by(year) %&gt;% \n  summarise(fff = min(dt))\n\ncolusa_fff_tbl\n\n# A tibble: 20 × 2\n    year fff       \n   &lt;dbl&gt; &lt;date&gt;    \n 1  2000 2000-11-12\n 2  2001 2001-11-27\n 3  2002 2002-12-23\n 4  2003 2003-11-22\n 5  2004 2004-11-29\n 6  2005 2005-12-04\n 7  2006 2006-11-28\n 8  2007 2007-12-01\n 9  2008 2008-12-10\n10  2009 2009-11-13\n11  2010 2010-11-23\n12  2011 2011-12-04\n13  2012 2012-12-15\n14  2013 2013-11-24\n15  2015 2015-11-25\n16  2016 2016-12-06\n17  2017 2017-12-11\n18  2018 2018-11-14\n19  2019 2019-11-24\n20  2020 2020-11-10"
  },
  {
    "objectID": "03_agroclimate-metrics.html#freeze-free-season",
    "href": "03_agroclimate-metrics.html#freeze-free-season",
    "title": "3  AgroClimate Metrics",
    "section": "3.7 Freeze-Free Season",
    "text": "3.7 Freeze-Free Season\nThe Freeze-Free Season (FFS) is calculated as the difference between the LSF and FFF (FFF [minus] LSF) (Parker et al. 2022). Since we already calculated LSF and FFF, computing the Freeze-Free Season can be done with a simple table join:\n\ncolusa_lf_fff_tbl &lt;- colusa_lf_tbl %&gt;% left_join(colusa_fff_tbl, by = \"year\")\ncolusa_lf_fff_tbl %&gt;% head()\n\n# A tibble: 6 × 3\n   year lf         fff       \n  &lt;dbl&gt; &lt;date&gt;     &lt;date&gt;    \n1  2000 2000-01-28 2000-11-12\n2  2001 2001-04-10 2001-11-27\n3  2002 2002-03-18 2002-12-23\n4  2003 2003-02-08 2003-11-22\n5  2004 2004-01-05 2004-11-29\n6  2005 2005-01-30 2005-12-04\n\ncolusa_lf_fff_ffs_tbl &lt;- colusa_lf_fff_tbl %&gt;% mutate(ffs = fff - lf)\ncolusa_lf_fff_ffs_tbl\n\n# A tibble: 20 × 4\n    year lf         fff        ffs     \n   &lt;dbl&gt; &lt;date&gt;     &lt;date&gt;     &lt;drtn&gt;  \n 1  2000 2000-01-28 2000-11-12 289 days\n 2  2001 2001-04-10 2001-11-27 231 days\n 3  2002 2002-03-18 2002-12-23 280 days\n 4  2003 2003-02-08 2003-11-22 287 days\n 5  2004 2004-01-05 2004-11-29 329 days\n 6  2005 2005-01-30 2005-12-04 308 days\n 7  2006 2006-02-20 2006-11-28 281 days\n 8  2007 2007-03-01 2007-12-01 275 days\n 9  2008 2008-04-20 2008-12-10 234 days\n10  2009 2009-03-23 2009-11-13 235 days\n11  2011 2011-02-28 2011-12-04 279 days\n12  2012 2012-03-23 2012-12-15 267 days\n13  2013 2013-02-26 2013-11-24 271 days\n14  2014 2014-02-04 NA          NA days\n15  2015 2015-01-03 2015-11-25 326 days\n16  2016 2016-01-01 2016-12-06 340 days\n17  2017 2017-02-28 2017-12-11 286 days\n18  2018 2018-03-05 2018-11-14 254 days\n19  2019 2019-01-04 2019-11-24 324 days\n20  2020 2020-01-04 2020-11-10 311 days"
  },
  {
    "objectID": "03_agroclimate-metrics.html#tropical-nights-and-hot-days",
    "href": "03_agroclimate-metrics.html#tropical-nights-and-hot-days",
    "title": "3  AgroClimate Metrics",
    "section": "3.8 Tropical Nights and Hot Days",
    "text": "3.8 Tropical Nights and Hot Days\nTropical Nights (TRN) are calculated as the number of nights per year with Tn &gt; 20 °C (68 °F) (Parker et al. 2022). This can be computed with:\n\ncolusa_tn_tbl &lt;- colusa_tbl %&gt;% \n  filter(cvar == \"tmmn\", temp_f &gt; set_units(20, degC)) %&gt;% \n  group_by(year) %&gt;% \n  summarise(tn = n())\n\ncolusa_tn_tbl\n\n# A tibble: 18 × 2\n    year    tn\n   &lt;dbl&gt; &lt;int&gt;\n 1  2000    10\n 2  2001     8\n 3  2002     3\n 4  2003    10\n 5  2004     1\n 6  2005     4\n 7  2006    12\n 8  2007     6\n 9  2008     6\n10  2009     3\n11  2011     2\n12  2012     3\n13  2013    13\n14  2015    10\n15  2017    15\n16  2018     2\n17  2019     3\n18  2020    13\n\n\n\n\nHot Days (HD) are defined as when Tx &gt; 38 °C (Parker et al. 2022). The number of hot days per year can be computed with:\n\ncolusa_hd_tbl &lt;- colusa_tbl %&gt;% \n  filter(cvar == \"tmmx\", temp_f &gt; set_units(38, degC)) %&gt;% \n  group_by(year) %&gt;% \n  summarise(hd = n())\n\ncolusa_hd_tbl\n\n# A tibble: 21 × 2\n    year    hd\n   &lt;dbl&gt; &lt;int&gt;\n 1  2000    15\n 2  2001    17\n 3  2002    15\n 4  2003    14\n 5  2004     7\n 6  2005    20\n 7  2006    20\n 8  2007     8\n 9  2008    21\n10  2009    26\n# ℹ 11 more rows"
  },
  {
    "objectID": "03_agroclimate-metrics.html#extreme-heat-days",
    "href": "03_agroclimate-metrics.html#extreme-heat-days",
    "title": "3  AgroClimate Metrics",
    "section": "3.9 Extreme Heat Days",
    "text": "3.9 Extreme Heat Days\nExtreme Heat Days (EHD) are the number of days per year with Tx &gt;98th percentile of summer (June-August) Tx for the 1981–2010 period (Parker et al. 2022). This is similar to HD, but with a threshold value based on the historic record. We can compute the 98th percentile of daily summertime highs with:\n\ncolusa_ehd_thresh &lt;- ca_loc_pt(coords = c(-122.159304, 39.289291)) %&gt;%\n  ca_slug(\"tmmx_day_gridmet\") %&gt;%\n  ca_years(start = 1981, end = 2010) %&gt;% \n  ca_getvals_tbl(quiet = TRUE) %&gt;% \n  filter(month(as.Date(dt)) %in% c(6,7,8)) %&gt;% \n  pull(val) %&gt;% \n  quantile(0.98) %&gt;% \n  set_units(degF)\n\ncolusa_ehd_thresh\n\n106.2176 [degF]\n\n\n\n\nOnce we have that threshold, we can compute Extreme Heat Days with:\n\ncolusa_ehd_tbl &lt;- colusa_tbl %&gt;% \n  filter(cvar == \"tmmx\", temp_f &gt; colusa_ehd_thresh) %&gt;% \n  group_by(year) %&gt;% \n  summarise(hd = n())\n\ncolusa_ehd_tbl\n\n# A tibble: 17 × 2\n    year    hd\n   &lt;dbl&gt; &lt;int&gt;\n 1  2001     1\n 2  2002     1\n 3  2003     4\n 4  2005     2\n 5  2006     7\n 6  2007     1\n 7  2008     4\n 8  2009     3\n 9  2010     1\n10  2012    10\n11  2013    12\n12  2014     2\n13  2015     1\n14  2017     8\n15  2018     1\n16  2019     1\n17  2020     3"
  },
  {
    "objectID": "03_agroclimate-metrics.html#heatwaves",
    "href": "03_agroclimate-metrics.html#heatwaves",
    "title": "3  AgroClimate Metrics",
    "section": "3.10 Heatwaves",
    "text": "3.10 Heatwaves\nHeatwave events (HW) are defined as 3+ consecutive days with Tx &gt; 98th percentile of 1981–2010 summer Tx (as in EHD) (Parker et al. 2022). Using the technique described in [Chapter 4 - Counting Consecutive Events][Counting Consecutive Events], we can compute the number of heatwaves per year.\n\nAdd a column for extreme heat day, then create a grouped tibble (by year):\n\n\ncolusa_grpd_tbl &lt;- colusa_tbl %&gt;% \n  filter(cvar == \"tmmx\") %&gt;% \n  mutate(ehd = temp_f &gt; colusa_ehd_thresh) %&gt;%\n  group_by(year) %&gt;% \n  arrange(dt)\n\nglimpse(colusa_grpd_tbl)\n\nRows: 7,671\nColumns: 5\nGroups: year [21]\n$ year   &lt;dbl&gt; 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 200…\n$ dt     &lt;date&gt; 2000-01-01, 2000-01-02, 2000-01-03, 2000-01-04, 2000-01-05, 20…\n$ cvar   &lt;chr&gt; \"tmmx\", \"tmmx\", \"tmmx\", \"tmmx\", \"tmmx\", \"tmmx\", \"tmmx\", \"tmmx\",…\n$ temp_f [degF] 54.95 [degF], 53.87 [degF], 57.65 [degF], 49.37 [degF], 57.47 …\n$ ehd    &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, …\n\n\n\n\n\nCreate a function that we can pass to group_modify(), will return the number of heatwaves per group (year):\n\n\nnum_hw &lt;- function(data_tbl, key_tbl, num_days = 3) {\n  rle_lst &lt;- rle(data_tbl$ehd)\n  tibble(num_hw = sum(rle_lst$values & rle_lst$lengths &gt;= num_days))\n}\n\n \n\nApply the heatwave function to the grouped tibble:\n\n\ncolusa_hw_tbl &lt;- colusa_grpd_tbl %&gt;% \n  group_modify(.f = num_hw, num_days = 3)\n\ncolusa_hw_tbl\n\n# A tibble: 21 × 2\n# Groups:   year [21]\n    year num_hw\n   &lt;dbl&gt;  &lt;int&gt;\n 1  2000      0\n 2  2001      0\n 3  2002      0\n 4  2003      0\n 5  2004      0\n 6  2005      0\n 7  2006      1\n 8  2007      0\n 9  2008      1\n10  2009      0\n# ℹ 11 more rows"
  },
  {
    "objectID": "03_agroclimate-metrics.html#diurnal-temperature-range",
    "href": "03_agroclimate-metrics.html#diurnal-temperature-range",
    "title": "3  AgroClimate Metrics",
    "section": "3.11 Diurnal Temperature Range",
    "text": "3.11 Diurnal Temperature Range\nDiurnal Temperature Range (DTR) is the difference between daily Tx and Tn (Parker et al. 2022). Below we calculate DTR over 1 March to 1 November.\n\ncolusa_dtr_tbl &lt;- colusa_tbl %&gt;% \n  filter(month(dt) %in% 3:10) %&gt;% \n  pivot_wider(id_cols = c(year, dt), names_from = cvar, values_from = temp_f) %&gt;% \n  mutate(dtr = tmmx - tmmn)\n\nhead(colusa_dtr_tbl)\n\n# A tibble: 6 × 5\n   year dt           tmmn   tmmx    dtr\n  &lt;dbl&gt; &lt;date&gt;     [degF] [degF] [degF]\n1  2000 2000-03-01   35.7   62.7  27.0 \n2  2000 2000-03-02   45.9   55.5   9.54\n3  2000 2000-03-03   36.6   68.6  32.0 \n4  2000 2000-03-04   41.1   62.1  21.1 \n5  2000 2000-03-05   46.3   55.5   9.18\n6  2000 2000-03-06   43.6   56.4  12.8 \n\n\n\nggplot(colusa_dtr_tbl %&gt;% mutate(year = as.factor(year)), aes(x=year, y = dtr)) + \n  geom_boxplot() + \n  labs(title = \"Diurnal Temperature Range, 2000-2020\",\n       subtitle = \"Colusa, CA\", \n       caption = \"Dataset: gridMet. Temporal period: March - October\",\n       x = \"\", y = \"daily temperature range\")"
  },
  {
    "objectID": "03_agroclimate-metrics.html#reference-evapotranspiration",
    "href": "03_agroclimate-metrics.html#reference-evapotranspiration",
    "title": "3  AgroClimate Metrics",
    "section": "3.12 Reference Evapotranspiration",
    "text": "3.12 Reference Evapotranspiration\nETo is calculated following the FAO Penman–Monteith method (Allen and United Nations 1998). We calculate summer (June-August) average ETo for each year 1981–2020 for our analysis. ETo units are mm (Parker et al. 2022).\n\nMore coming soon…\n\n\n\n\n\nAllen, R. G., and Food and Agriculture Organization of the United Nations, eds. 1998. Crop Evapotranspiration: Guidelines for Computing Crop Water Requirements. FAO Irrigation and Drainage Paper 56. Rome: Food; Agriculture Organization of the United Nations.\n\n\nLuedeling, Eike, and Patrick H. Brown. 2011. “A Global Analysis of the Comparability of Winter Chill Models for Fruit and Nut Trees.” International Journal of Biometeorology 55 (3): 411–21. https://doi.org/10.1007/s00484-010-0352-y.\n\n\nMcMaster, G, and W Wilhelm. 1997. “Growing Degree-Days: One Equation, Two Interpretations.” Agricultural and Forest Meteorology 87 (4): 291–300. https://doi.org/10.1016/S0168-1923(97)00027-0.\n\n\nParker, Lauren E., Ning Zhang, John T. Abatzoglou, Steven M. Ostoja, and Tapan B. Pathak. 2022. “Observed Changes in Agroclimate Metrics Relevant for Specialty Crop Production in California.” Agronomy 12 (1): 205. https://doi.org/10.3390/agronomy12010205."
  },
  {
    "objectID": "04_degday-chill.html",
    "href": "04_degday-chill.html",
    "title": "4  Degree Days",
    "section": "",
    "text": "A common application of weather and climate data is predicting phenological events like egg laying for insects, or fruit ripening for tree crops. These predictions are possible due to research which has modeled the relationship between phenology and accumulated heat, or degree days.\nThe researchers who study the relationship between phenology and accumulated heat use several calculations to measure degree days. Many of the most common degree day formulas can be found in the degday R package.\nhttps://ucanr-igis.github.io/degday/\nAll you need after that are the phenology tables.\nExample: https://ucanr-igis.shinyapps.io/noworm/\n\nMore coming soon…"
  },
  {
    "objectID": "05_agroclimate-rasters.html",
    "href": "05_agroclimate-rasters.html",
    "title": "5  Agroclimate Rasters",
    "section": "",
    "text": "This chapter will show how to\n\ntake a raster time series of observed (or modeled) weather data\n\n\nSpatial CIMIS\ngridMet\nPRISM\n\n\nConvert it to stars (see caladaptr)\nTeach them how to use sapply to compute the agroclimate metric pixel-by-pixel\n\nkey thing is to reduce the computation to a function that takes a timeseries vector and spits out the agroclimate metric\n\n\nExample: Compute the number of days &gt; 105 degF for one growing season (Apr - Sep) for a small county\nVisualize multi-year agroclimate metric rasters with animation, or a slideshow kind of thing"
  },
  {
    "objectID": "06_modeled-climate-data.html",
    "href": "06_modeled-climate-data.html",
    "title": "6  Modeled Climate Data",
    "section": "",
    "text": "Similarities and differences between observed weather data and modeled climate data\nObserved weather data represent a single series of weather outcomes.\n‘Climate’ is the ‘envelope’ or variability of weather. You need at least 30 years of observed weather data to see the envelope.\nModeled climate data are based on simulations of weather (hourly). Just like observed weather data, you need 30 years of simulated weather to characterize the envelope.\nThe simulated weather data from a climate model are not meant to be predictive. But the envelope of many ‘runs’ of the simulation do a good job at predicting the climate envelope.\nYou can compute future agroclimate metrics with projected climate data, provided you have access to the simulated weather (e.g., daily temperature). This is basically the same as computing the metric with observed data.\nThe tricky part comes when analzing the results, because\n\nThere is not one projected climate future, but many (different CGMs, different emissions scenarios, different runs)\nTherefore you have a range of projected agroclimate metrics. You have to characterize them as a group / probabilistically"
  },
  {
    "objectID": "07_climate-analogues.html#climate-analogues",
    "href": "07_climate-analogues.html#climate-analogues",
    "title": "7  AgroClimate Analogues",
    "section": "7.1 Climate Analogues",
    "text": "7.1 Climate Analogues\nThe following is just placeholder text, which needs to be updated with some actual definitions and citations.\nClimate analogues refer to locations that have the same climate profile. For example California and Spain might be considered climate analogues, because they both have temperate, moderate climates, with a similar distribution of rainfall.\nA modeled climate analogue is a location that currently has the climate that is projected to occur somewhere else. For example, Sacramento’s climate analog 50 year from now might be Bakersfield. That means Bakersfield already has the weather envelope that Sacromentons can expect to see 50 years from now.\nClimate analogues are useful because they make the effects of climate change more understandable. For example if I live in Sacramento and want to know what kind of street trees will be viable in 50 years, or what kind of cooling systems will be needed in houses, I don’t have to run fancy models. All I have to do is take a trip to Bakerfield and ‘see the future’.\nBut what does it mean to have “similar” climates? This is where metrics come in, because the answer depends on your use case. If you’re interested in what kind of trees to plant in your orchard, you’d probably want to define ‘similarity’ based on a metric like winter chill. If you’re building an irrigation system, you might want to look at models of evapotranspiration."
  },
  {
    "objectID": "07_climate-analogues.html#example",
    "href": "07_climate-analogues.html#example",
    "title": "7  AgroClimate Analogues",
    "section": "7.2 Example",
    "text": "7.2 Example\nsee McBride and Laćan (2018) (they used the temperature of hottest day in July as a metric for urban tree species viability)\nuse CalAdaptR to compare historical modeled July temps with future historic modeled July temps\ndo this for all preset areas of interest the CalAdapt server - Or I could use a place names layer\n\n\n\n\nMcBride, Joe R., and Igor Laćan. 2018. “The Impact of Climate-Change Induced Temperature Increases on the Suitability of Street Tree Species in California (USA) Cities.” Urban Forestry & Urban Greening 34 (August): 348–56. https://doi.org/10.1016/j.ufug.2018.07.020."
  },
  {
    "objectID": "99_other.html#frost",
    "href": "99_other.html#frost",
    "title": "8  Other Examples",
    "section": "8.1 Frost",
    "text": "8.1 Frost\n(Parker, Pathak, and Ostoja 2021)\nThey computed hours # of frost exposure, where temperature thresholds were based on i) crop and ii) temperature range (colder = more exposure. Compared changes in this relative metric past, present, and future.\n\nThe frequency of frost temperatures under observed contemporary and projected future climate conditions were assessed in units of hours of exposure, quantified using daily maximum and minimum temperatures temporally disaggregated to hourly data using a modified sine curve approach (Linvill, 1990)…In assessing frost exposure that is not crop-specific, we highlight the frost exposure (in hours) for three threshold temperatures (T) – -2 °C, 0 °C, and 2 °C – that encapsulate the most frost-tender phase of development for many high-value fruit and nut trees (e.g., Gholipour, 2006; WSU, 2020)."
  },
  {
    "objectID": "99_other.html#pest-development",
    "href": "99_other.html#pest-development",
    "title": "8  Other Examples",
    "section": "8.2 Pest Development",
    "text": "8.2 Pest Development\n(Pathak, Maskey, and Rijal 2021)\nThey used degree day models to compare past and future patterns of NOW development (timing, generation length, number of generations).\n\nThe objective of this study was to quantify changes in the biofix, lifecycle length, and number of generations for these pests for the entire Central Valley of California. Using a well-established growing-degree days (GDD) model calibrated and validated using observations from orchards of California, and climate change projections from the Coupled Model Intercomparison Project phases 5 and 6 (CMIP5 and CMIP6) General Circulation Models, we found that biofix dates of these pests are expected to shift earlier by up to 28 days, and length of generations is expected to be shortened by up to 19 days, and up to 1.4 extra generations of these pests can be added by the end of the century depending on the scenario.\n\n\n\n(Jha et al. 2024)\nSimilar to above, but more pests.\n\nThe objective of this study was to quantify changes in the biofix, lifecycle length, and number of generations for these pests for the entire Central Valley of California. Using a well-established growing-degree days (GDD) model calibrated and validated using observations from orchards of California, and climate change projections from the Coupled Model Intercomparison Project phases 5 and 6 (CMIP5 and CMIP6) General Circulation Models, we found that biofix dates of these pests are expected to shift earlier by up to 28 days, and length of generations is expected to be shortened by up to 19 days, and up to 1.4 extra generations of these pests can be added by the end of the century depending on the scenario.\n\n\n\n\n\nJha, Prakash Kumar, Ning Zhang, Jhalendra P. Rijal, Lauren E. Parker, Steven Ostoja, and Tapan B. Pathak. 2024. “Climate Change Impacts on Insect Pests for High Value Specialty Crops in California.” Science of The Total Environment 906 (January): 167605. https://doi.org/10.1016/j.scitotenv.2023.167605.\n\n\nParker, Lauren E., Tapan Pathak, and Steven Ostoja. 2021. “Climate Change Reduces Frost Exposure for High-Value California Orchard Crops.” Science of The Total Environment 762 (March): 143971. https://doi.org/10.1016/j.scitotenv.2020.143971.\n\n\nPathak, Tapan, Mahesh Maskey, and Jhalendra P. Rijal. 2021. “Impact of Climate Change on Navel Orangeworm, a Major Pest of Tree Nuts in California.” Science of The Total Environment 755 (February): 142657. https://doi.org/10.1016/j.scitotenv.2020.142657."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Allen, R. G., and Food and Agriculture Organization of the United\nNations, eds. 1998. Crop Evapotranspiration: Guidelines for\nComputing Crop Water Requirements. FAO Irrigation and\nDrainage Paper 56. Rome: Food; Agriculture Organization of the United\nNations.\n\n\nJha, Prakash Kumar, Ning Zhang, Jhalendra P. Rijal, Lauren E. Parker,\nSteven Ostoja, and Tapan B. Pathak. 2024. “Climate Change Impacts\non Insect Pests for High Value Specialty Crops in\nCalifornia.” Science of The Total\nEnvironment 906 (January): 167605. https://doi.org/10.1016/j.scitotenv.2023.167605.\n\n\nLuedeling, Eike, and Patrick H. Brown. 2011. “A Global Analysis of\nthe Comparability of Winter Chill Models for Fruit and Nut\nTrees.” International Journal of Biometeorology 55 (3):\n411–21. https://doi.org/10.1007/s00484-010-0352-y.\n\n\nMcBride, Joe R., and Igor Laćan. 2018. “The Impact of\nClimate-Change Induced Temperature Increases on the Suitability of\nStreet Tree Species in California (USA)\nCities.” Urban Forestry & Urban Greening 34\n(August): 348–56. https://doi.org/10.1016/j.ufug.2018.07.020.\n\n\nMcMaster, G, and W Wilhelm. 1997. “Growing Degree-Days: One\nEquation, Two Interpretations.” Agricultural and Forest\nMeteorology 87 (4): 291–300. https://doi.org/10.1016/S0168-1923(97)00027-0.\n\n\nParker, Lauren E., Tapan Pathak, and Steven Ostoja. 2021. “Climate\nChange Reduces Frost Exposure for High-Value California\nOrchard Crops.” Science of The Total Environment 762\n(March): 143971. https://doi.org/10.1016/j.scitotenv.2020.143971.\n\n\nParker, Lauren E., Ning Zhang, John T. Abatzoglou, Steven M. Ostoja, and\nTapan B. Pathak. 2022. “Observed Changes in\nAgroclimate Metrics Relevant for\nSpecialty Crop Production in\nCalifornia.” Agronomy 12 (1): 205. https://doi.org/10.3390/agronomy12010205.\n\n\nPathak, Tapan, Mahesh Maskey, and Jhalendra P. Rijal. 2021.\n“Impact of Climate Change on Navel Orangeworm, a Major Pest of\nTree Nuts in California.” Science of The Total\nEnvironment 755 (February): 142657. https://doi.org/10.1016/j.scitotenv.2020.142657."
  },
  {
    "objectID": "02_metrics-methods.html#working-with-date-and-time-columns",
    "href": "02_metrics-methods.html#working-with-date-and-time-columns",
    "title": "2  Methods for Computing Metrics",
    "section": "2.3 Working with Date and Time Columns",
    "text": "2.3 Working with Date and Time Columns\nThis is really important. As part of importing weather data, you often have to do some wrangling with date and time columns.\nBefore you start computing metrics,\n\nDate columns should be converted to R Date class\nDate-time columns should be saved as POSIXct objects\n\n\n2.3.1 Converting Character Date and Time Columns\nShow them all the lubridate functions. (see Lubridate cheatsheet)\n\n\n2.3.2 Combining Separate Date and Time Part Columns\nShow code here. Concatenate date part fields with lubridate::make_date() and lubridate::make_datetime()\n\n\n2.3.3 Converting Across Time Zones\nNote there’s a difference between assigning time zones and converting POSIXct objects to different time zones.\n\n\n2.3.4 Saving Date and Time Data Locally\nIf you need to save your weather data to disk, use a format that knows how to save dates and times (e.g., geopackage, native R data file).\nIf you need to save it in a text format (e.g., csv) or as spreadsheet (e.g., xlsx, Google Sheet), use lubridate::format_ISO8601() to write, and lubridate::ymd_hms() to bring it back in."
  }
]